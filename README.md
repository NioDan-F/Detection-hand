
# ğŸ–ï¸ Hand Gesture Recognition using Decision Tree on ESP32-CAM

This project implements a real-time **hand gesture recognition system** using a **Decision Tree classifier** trained in Python and deployed on an **ESP32-CAM**. It uses **HOG (Histogram of Oriented Gradients)** for feature extraction and classifies gestures into 3 labels (`00500A`, `00500B`, `00500C`).

## ğŸ” Overview

- ğŸ§  Trained a Decision Tree model using scikit-learn on extracted HOG features from hand gesture images.
- ğŸ“¦ Model is exported as C++ code using `everywhereml` format, embedded into ESP32-CAM firmware.
- ğŸ¥ ESP32-CAM captures hand image, extracts HOG features, and predicts gesture in real time.

## ğŸ§  Machine Learning Details

- **Feature extraction**: HOG with block size 8, 9 bins, resized to 28x28
- **Classifier**: DecisionTreeClassifier (`max_depth=30`)
- **Model output**: 3 classes with labels: `00500A`, `00500B`, `00500C`
- Model logic located in: `HogClassifier.h`

## ğŸ“¦ Project Structure

```
â”œâ”€â”€ decision.ipynb              # Python notebook for training Decision Tree & exporting model
â”œâ”€â”€ ESP32CAM_Detection.ino      # Main Arduino sketch for ESP32-CAM (reads image, predicts)
â”œâ”€â”€ HogPipeline.h               # HOG feature extraction pipeline
â”œâ”€â”€ HogClassifier.h             # Decision Tree model in C++
â”œâ”€â”€ README.md                   # Project documentation
```

## ğŸš€ How It Works

1. **Data preparation**: Hand gesture images collected and labeled.
2. **Feature extraction**: Convert grayscale, resize to 28Ã—28, extract HOG features.
3. **Model training**: Decision Tree trained via `sklearn`, exported to C++.
4. **ESP32-CAM**:
    - Captures frame from camera.
    - Converts to grayscale, applies HOG, then predicts with the embedded model.
    - Returns class label via Serial output.

## ğŸ’» Dependencies

### On PC (Python):
- Python â‰¥ 3.8
- `opencv-python`
- `scikit-learn`
- `joblib`, `numpy`
- `everywhereml` for model export

### On ESP32-CAM:
- Arduino core for ESP32
- `esp32cam` or `esp_camera` library

## ğŸ“· Labels / Gestures

| Label    | Description       |
|----------|-------------------|
| 00500A   | (kÃ½ tá»± A)         |
| 00500B   | (KÃ½ tá»± B)         |
| 00500C   | (KÃ½ tá»± C)         |

## ğŸ› ï¸ Getting Started

1. Train model with `decision.ipynb`.
2. Upload code to ESP32-CAM via Arduino IDE (`ESP32CAM_Detection.ino`).
3. Connect Serial Monitor to see predicted gesture output.
4. Test with hand gestures in front of the ESP32-CAM.

## ğŸ‘¤ Author

**Quyet Ba (aka NioDan-F)**  
ğŸ“§ [quyet1hai@gmail.com](mailto:quyet1hai@gmail.com)
